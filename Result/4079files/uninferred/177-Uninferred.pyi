from typing import Any
from yarll.agents.agent import Agent

class A2C(Agent):
    monitor_path: Any = ...
    env: Any = ...
    initial_features: Any = ...
    ac_net: Any = ...
    action: Any = ...
    states: Any = ...
    actions_taken: Any = ...
    advantage: Any = ...
    ret: Any = ...
    vars: Any = ...
    _global_step: Any = ...
    optimizer: Any = ...
    n_steps: Any = ...
    train_op: Any = ...
    init_op: Any = ...
    session: Any = ...
    saver: Any = ...
    loss_summary_op: Any = ...
    writer: Any = ...
    env_runner: Any = ...
    def __init__(self, env: Any, monitor_path: str, video: bool=..., **usercfg: Any) -> None: ...
    def _initialize(self) -> None: ...
    def build_networks(self): ...
    def make_loss(self): ...
    @property
    def global_step(self): ...
    def get_critic_value(self, state: Any, features: Any): ...
    def choose_action(self, state: Any, features: Any) -> dict: ...
    def get_env_action(self, action: Any) -> int: ...
    def learn(self) -> None: ...

class A2CDiscrete(A2C):
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    ac_net: Any = ...
    def build_networks(self) -> None: ...
    def make_loss(self): ...

class A2CDiscreteCNN(A2CDiscrete):
    ac_net: Any = ...
    def build_networks(self) -> None: ...

class A2CDiscreteCNNRNN(A2CDiscrete):
    ac_net: Any = ...
    initial_features: Any = ...
    def build_networks(self) -> None: ...
    def choose_action(self, state: Any, features: Any) -> dict: ...
    def get_critic_value(self, states: Any, features: Any): ...

class A2CContinuous(A2C):
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    ac_net: Any = ...
    def build_networks(self) -> None: ...
    def make_loss(self): ...
    def get_env_action(self, action: Any): ...

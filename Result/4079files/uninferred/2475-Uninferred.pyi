import pendulum
from collections import namedtuple
from common import PreparedVideoInfo, VideoMetadata, VideoProvider
from datetime import date
from typing import Any, Iterable, Optional

Project = namedtuple('Project', ['id', 'name'])

NeulionClip = namedtuple('Clip', ['url', 'title', 'rank', 'descr', 'start_utc', 'project', 'id', 'duration'])

class NeulionClipMetadata(VideoMetadata):
    project_id: Any = ...
    rank: Any = ...
    descr: Any = ...
    clip_start_utc: Any = ...
    duration: Any = ...
    def __init__(self, clip_id: Any, project_id: Any, rank: Any, title: Any, descr: Any, clip_start_utc: Any, url: Any, category: Optional[Any] = ..., timecodes: Optional[Any] = ...) -> None: ...

class NeulionScraperApi(VideoProvider):
    tz: Any = ...
    _site_soup: Any = ...
    session: Any = ...
    def __init__(self, site_url: Any, tz: str = ...) -> None: ...
    def available_dates(self, start_date: date, end_date: date) -> Iterable[pendulum.Date]: ...
    def get_metadata(self, for_date: Any) -> Iterable[VideoMetadata]: ...
    def download(self, url: Any, destination_dir: Any) -> None: ...
    def postprocess(self, video_metadata: VideoMetadata, download_dir: Any, destination_dir: Any, **kwargs: Any) -> PreparedVideoInfo: ...
    def _get_site_html(self): ...
    def projects(self) -> None: ...
    def allowed_dates(self) -> None: ...
    def clips(self, for_date: date, project_ids: Any) -> Any: ...

def parse_time_range_from_url(adaptive_url: Any): ...
def group_video_clips(clips: Any): ...
def group_all_clips_under_first_clip(clips: Any): ...
def duration_to_timecode(delta: Any): ...
def timecode_to_duration(code: Any): ...
def calculate_timecodes(root_clip: Any, subclips: Any): ...
def adaptive_url_to_segment_urls(adaptive_url: Any) -> None: ...
